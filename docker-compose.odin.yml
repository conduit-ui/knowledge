services:
  qdrant:
    image: qdrant/qdrant:latest
    container_name: knowledge-qdrant
    restart: unless-stopped
    ports:
      - "100.68.122.24:6333:6333"  # HTTP API - Tailscale only
      - "100.68.122.24:6334:6334"  # gRPC API - Tailscale only
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/6333"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    container_name: knowledge-redis
    restart: unless-stopped
    ports:
      - "100.68.122.24:6380:6379"  # Tailscale only
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  embeddings:
    build:
      context: ./docker/embedding-server
      dockerfile: Dockerfile
    container_name: knowledge-embeddings
    restart: unless-stopped
    ports:
      - "100.68.122.24:8001:8001"  # Tailscale only
    volumes:
      - embedding_cache:/root/.cache
    environment:
      - EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
      - DEVICE=cpu
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8001/health')"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  qdrant_storage:
    driver: local
  redis_data:
    driver: local
  embedding_cache:
    driver: local

networks:
  default:
    name: knowledge-network
